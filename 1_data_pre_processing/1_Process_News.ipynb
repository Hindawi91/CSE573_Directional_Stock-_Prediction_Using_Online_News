{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1616366345156,
     "user": {
      "displayName": "Abhishek Devasya Venkatramana",
      "photoUrl": "",
      "userId": "06922042641627792474"
     },
     "user_tz": 420
    },
    "id": "EW_KdqRdwAHy"
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import json\n",
    "from datetime import datetime, timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords, words\n",
    "from nltk.stem import LancasterStemmer, PorterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 340,
     "status": "ok",
     "timestamp": 1616364820543,
     "user": {
      "displayName": "Abhishek Devasya Venkatramana",
      "photoUrl": "",
      "userId": "06922042641627792474"
     },
     "user_tz": 420
    },
    "id": "esU05LDjwTQ5",
    "outputId": "280dccbe-1f17-47e4-826d-a28e45fd2a19"
   },
   "outputs": [],
   "source": [
    "NEWS_DIRECTORY = '../data/News/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/local/ASUAD/falhinda/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /home/local/ASUAD/falhinda/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/local/ASUAD/falhinda/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download libraries\n",
    "nltk.download('punkt')\n",
    "nltk.download('words')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "2yZGBQflwpNK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading JSON from 2018_07_d157b48c57be246ec7dd80e7af4388a2.zip: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "def get_news_articles(path):\n",
    "    news_text = []\n",
    "    news_publish_time = []\n",
    "    news_source = []\n",
    "    domains_to_select = ['ae', 'au', 'bb', 'biz', 'ca', 'in', 'io', 'net', 'uk', 'com']\n",
    "    \n",
    "    \n",
    "    with os.scandir(path) as news_directories:\n",
    "        for directory in news_directories:\n",
    "            with os.scandir(os.path.join(path, directory.name)) as folder:\n",
    "                for article in folder:\n",
    "                    with open(os.path.join(path, directory.name, article.name), encoding='latin1') as f:\n",
    "                        try:\n",
    "                            news_data = json.load(f)\n",
    "                        except json.JSONDecodeError as e:\n",
    "                            print(f\"Error loading JSON from {article.name}: {e}\")\n",
    "                            continue\n",
    "                    if 'site' in news_data['thread'] and news_data['thread']['site']:\n",
    "                        source = news_data['thread']['site'] \n",
    "                        domain = source.split('.')[-1]\n",
    "                        # Skip news from domain not in the list\n",
    "                        if domain not in domains_to_select:\n",
    "                            continue\n",
    "                        news_source.append(source)\n",
    "                    else:\n",
    "                        news_source.append(None)\n",
    "                    if 'published' in news_data and news_data['published']:\n",
    "                        news_publish_time.append(news_data['published'])\n",
    "                    else:\n",
    "                        news_publish_time.append(None)\n",
    "                    if 'text' in news_data and news_data['text']:\n",
    "                        news_text.append(news_data['text'])\n",
    "                    else:\n",
    "                        news_text.append(None)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'timestamp': news_publish_time,\n",
    "        'text': news_text,\n",
    "        'source': news_source,\n",
    "    })\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return df\n",
    "\n",
    "news_df = get_news_articles(NEWS_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-14T14:12:00.000+02:00</td>\n",
       "      <td>Reddit\\nThereâs been no shortage of AAPL pes...</td>\n",
       "      <td>9to5mac.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-05T02:00:00.000+02:00</td>\n",
       "      <td>By Mark DeCambre, MarketWatch\\nU.S. stock futu...</td>\n",
       "      <td>morningstar.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-05T14:45:00.000+02:00</td>\n",
       "      <td>Last month, I posted my quarterly results and ...</td>\n",
       "      <td>seekingalpha.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-26T02:00:00.000+02:00</td>\n",
       "      <td>By Cristina Roca\\nKering (KER.FR) is implement...</td>\n",
       "      <td>morningstar.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-23T02:00:00.000+02:00</td>\n",
       "      <td>Wall Street closed mostly higher on Wednesday ...</td>\n",
       "      <td>zacks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73496</th>\n",
       "      <td>2019-01-24T09:19:00.000+02:00</td>\n",
       "      <td>Shutterstock photo Top Tech Stocks\\nMSFT -1.08...</td>\n",
       "      <td>nasdaq.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73497</th>\n",
       "      <td>2019-01-14T22:18:00.000+02:00</td>\n",
       "      <td>As Microsoft (MSFT) Stock Declined, Shareholde...</td>\n",
       "      <td>moveefy.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73498</th>\n",
       "      <td>2018-12-31T02:00:00.000+02:00</td>\n",
       "      <td>Â© Reuters. US STOCKS-Wall Street falters afte...</td>\n",
       "      <td>investing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73499</th>\n",
       "      <td>2019-01-28T21:00:00.000+02:00</td>\n",
       "      <td>Apple Might Challenge Microsoft and Amazon Wit...</td>\n",
       "      <td>yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73500</th>\n",
       "      <td>2019-01-24T18:24:00.000+02:00</td>\n",
       "      <td>(1:30) - Do You Have The Guts To Be A Value In...</td>\n",
       "      <td>zacks.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73501 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           timestamp  \\\n",
       "0      2018-11-14T14:12:00.000+02:00   \n",
       "1      2018-11-05T02:00:00.000+02:00   \n",
       "2      2018-11-05T14:45:00.000+02:00   \n",
       "3      2018-11-26T02:00:00.000+02:00   \n",
       "4      2018-11-23T02:00:00.000+02:00   \n",
       "...                              ...   \n",
       "73496  2019-01-24T09:19:00.000+02:00   \n",
       "73497  2019-01-14T22:18:00.000+02:00   \n",
       "73498  2018-12-31T02:00:00.000+02:00   \n",
       "73499  2019-01-28T21:00:00.000+02:00   \n",
       "73500  2019-01-24T18:24:00.000+02:00   \n",
       "\n",
       "                                                    text            source  \n",
       "0      Reddit\\nThereâs been no shortage of AAPL pes...       9to5mac.com  \n",
       "1      By Mark DeCambre, MarketWatch\\nU.S. stock futu...   morningstar.com  \n",
       "2      Last month, I posted my quarterly results and ...  seekingalpha.com  \n",
       "3      By Cristina Roca\\nKering (KER.FR) is implement...   morningstar.com  \n",
       "4      Wall Street closed mostly higher on Wednesday ...         zacks.com  \n",
       "...                                                  ...               ...  \n",
       "73496  Shutterstock photo Top Tech Stocks\\nMSFT -1.08...        nasdaq.com  \n",
       "73497  As Microsoft (MSFT) Stock Declined, Shareholde...       moveefy.com  \n",
       "73498  Â© Reuters. US STOCKS-Wall Street falters afte...     investing.com  \n",
       "73499  Apple Might Challenge Microsoft and Amazon Wit...         yahoo.com  \n",
       "73500  (1:30) - Do You Have The Guts To Be A Value In...         zacks.com  \n",
       "\n",
       "[73501 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "Q6GUZqZi7M3u"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp    0\n",
       "text         0\n",
       "source       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timezone to UTC and drop the timezone\n",
    "news_df['timestamp'] = news_df['timestamp'].apply(lambda x: datetime.fromisoformat(x).astimezone(tz=timezone.utc))\n",
    "news_df['timestamp'] = news_df['timestamp'].dt.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_df['time'] = news_df['publish_timestamp'].apply(lambda x: x.time())\n",
    "# news_df['date'] = news_df['publish_timestamp'].apply(lambda x: x.date())\n",
    "news_df['text'] = news_df['text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df.to_csv('RawNewsData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-14 12:12:00</td>\n",
       "      <td>reddit\\nthereâs been no shortage of aapl pes...</td>\n",
       "      <td>9to5mac.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-05 00:00:00</td>\n",
       "      <td>by mark decambre, marketwatch\\nu.s. stock futu...</td>\n",
       "      <td>morningstar.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-05 12:45:00</td>\n",
       "      <td>last month, i posted my quarterly results and ...</td>\n",
       "      <td>seekingalpha.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-26 00:00:00</td>\n",
       "      <td>by cristina roca\\nkering (ker.fr) is implement...</td>\n",
       "      <td>morningstar.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-23 00:00:00</td>\n",
       "      <td>wall street closed mostly higher on wednesday ...</td>\n",
       "      <td>zacks.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73496</th>\n",
       "      <td>2019-01-24 07:19:00</td>\n",
       "      <td>shutterstock photo top tech stocks\\nmsft -1.08...</td>\n",
       "      <td>nasdaq.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73497</th>\n",
       "      <td>2019-01-14 20:18:00</td>\n",
       "      <td>as microsoft (msft) stock declined, shareholde...</td>\n",
       "      <td>moveefy.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73498</th>\n",
       "      <td>2018-12-31 00:00:00</td>\n",
       "      <td>â© reuters. us stocks-wall street falters afte...</td>\n",
       "      <td>investing.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73499</th>\n",
       "      <td>2019-01-28 19:00:00</td>\n",
       "      <td>apple might challenge microsoft and amazon wit...</td>\n",
       "      <td>yahoo.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73500</th>\n",
       "      <td>2019-01-24 16:24:00</td>\n",
       "      <td>(1:30) - do you have the guts to be a value in...</td>\n",
       "      <td>zacks.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73501 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp                                               text  \\\n",
       "0     2018-11-14 12:12:00  reddit\\nthereâs been no shortage of aapl pes...   \n",
       "1     2018-11-05 00:00:00  by mark decambre, marketwatch\\nu.s. stock futu...   \n",
       "2     2018-11-05 12:45:00  last month, i posted my quarterly results and ...   \n",
       "3     2018-11-26 00:00:00  by cristina roca\\nkering (ker.fr) is implement...   \n",
       "4     2018-11-23 00:00:00  wall street closed mostly higher on wednesday ...   \n",
       "...                   ...                                                ...   \n",
       "73496 2019-01-24 07:19:00  shutterstock photo top tech stocks\\nmsft -1.08...   \n",
       "73497 2019-01-14 20:18:00  as microsoft (msft) stock declined, shareholde...   \n",
       "73498 2018-12-31 00:00:00  â© reuters. us stocks-wall street falters afte...   \n",
       "73499 2019-01-28 19:00:00  apple might challenge microsoft and amazon wit...   \n",
       "73500 2019-01-24 16:24:00  (1:30) - do you have the guts to be a value in...   \n",
       "\n",
       "                 source  \n",
       "0           9to5mac.com  \n",
       "1       morningstar.com  \n",
       "2      seekingalpha.com  \n",
       "3       morningstar.com  \n",
       "4             zacks.com  \n",
       "...                 ...  \n",
       "73496        nasdaq.com  \n",
       "73497       moveefy.com  \n",
       "73498     investing.com  \n",
       "73499         yahoo.com  \n",
       "73500         zacks.com  \n",
       "\n",
       "[73501 rows x 3 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'text', 'source'], dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['timestamp', 'source', 'sentences']\n",
    "processed_amzn_news_df = pd.DataFrame(columns=columns)\n",
    "processed_aapl_news_df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20236 73175\n"
     ]
    }
   ],
   "source": [
    "# Extract and separate sentences containing AAPL and AMZN\n",
    "for index, row in news_df.iterrows():\n",
    "    text = row['text']\n",
    "    aapl_sentences, amzn_sentences = [], []\n",
    "    for sentence in nltk.sent_tokenize(text):\n",
    "        if 'amazon' in sentence or 'amzn' in sentence:\n",
    "            amzn_sentences.append(sentence)\n",
    "        if 'apple' in sentence or 'aapl' in sentence:\n",
    "            aapl_sentences.append(sentence)\n",
    "    if aapl_sentences:\n",
    "        processed_aapl_news_df.loc[len(processed_aapl_news_df)] = [row['timestamp'], row['source'], aapl_sentences]\n",
    "    if amzn_sentences:\n",
    "        processed_amzn_news_df.loc[len(processed_amzn_news_df)] = [row['timestamp'], row['source'], amzn_sentences]\n",
    "        \n",
    "print(len(processed_amzn_news_df), len(processed_aapl_news_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del news_df\n",
    "processed_amzn_news_df.to_csv('AmznExtractedSentences.csv')\n",
    "processed_aapl_news_df.to_csv('AaplExtractedSentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "def extract_words(input_words):\n",
    "    from nltk.corpus import words\n",
    "    \n",
    "    # Remove all non-ascii words\n",
    "    processed_words = [w for w in input_words if w.isascii()]\n",
    "    \n",
    "    # Remove punctuation words\n",
    "    tr_dict = str.maketrans(dict.fromkeys(string.punctuation))\n",
    "    processed_words = [w.translate(tr_dict) for w in processed_words if w]\n",
    "    \n",
    "    # Remove links\n",
    "    final_words = []\n",
    "    for word in processed_words:\n",
    "        if not re.match('[www]', word):\n",
    "            final_words.append(word)\n",
    "    \n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    processed_words = [w for w in final_words if w not in stop_words]\n",
    "    \n",
    "    # Stem words and return unique words\n",
    "    stemmer = SnowballStemmer('english')\n",
    "    seen = set()\n",
    "    processed_words = [stemmer.stem(word) for word in processed_words if word]\n",
    "    processed_words = [x for x in processed_words if not (x in seen or seen.add(x))]\n",
    "    del seen\n",
    "    \n",
    "    # Keep only words from English dictionary\n",
    "    english_words = set([w.lower() for w in words.words()])\n",
    "    processed_words = [w for w in processed_words if w in english_words]\n",
    "    \n",
    "    return processed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_df_columns = ['timestamp', 'source', 'tokens']\n",
    "tokenized_amzn_news_df = pd.DataFrame(columns=tokenized_df_columns)\n",
    "tokenized_aapl_news_df = pd.DataFrame(columns=tokenized_df_columns)\n",
    "\n",
    "print(\"\\n\\nProcessing %d records\" % len(processed_amzn_news_df))\n",
    "for index, row in processed_amzn_news_df.iterrows():\n",
    "    # This break is only for testing purpose\n",
    "#     if index >= 1000:\n",
    "#         break\n",
    "        \n",
    "    if index % 500 == 0:\n",
    "        print(\"Completed %d rows\" % index)\n",
    "    token_words = []\n",
    "    for sentence in row['sentences']:\n",
    "        token_words.extend(nltk.wordpunct_tokenize(sentence))\n",
    "    token_words = extract_words(token_words)\n",
    "    print(token_words)\n",
    "    tokenized_amzn_news_df.loc[index] = [\n",
    "        processed_amzn_news_df.loc[index]['timestamp'],\n",
    "        processed_amzn_news_df.loc[index]['source'], \n",
    "        token_words\n",
    "    ]\n",
    "tokenized_amzn_news_df.to_csv('AmznExtractedTokens.csv')\n",
    "\n",
    "\n",
    "print(\"\\n\\nProcessing %d records\" % len(processed_aapl_news_df))\n",
    "for index, row in processed_aapl_news_df.iterrows():\n",
    "    # This break is only for testing purpose\n",
    "#     if index >= 1000:\n",
    "#         break\n",
    "    if index % 500 == 0:\n",
    "        print(\"Completed %d rows\" % index)\n",
    "    token_words = []\n",
    "    for sentence in row['sentences']:\n",
    "        token_words.extend(nltk.wordpunct_tokenize(sentence))\n",
    "    token_words = extract_words(token_words)\n",
    "    print(token_words)\n",
    "    tokenized_aapl_news_df.loc[index] = [\n",
    "        processed_aapl_news_df.loc[index]['timestamp'], \n",
    "        processed_aapl_news_df.loc[index]['source'],\n",
    "        token_words\n",
    "    ]\n",
    "tokenized_aapl_news_df.to_csv('AaplExtractedTokens.csv')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-14 12:12:00</td>\n",
       "      <td>9to5mac.com</td>\n",
       "      <td>['thing', 'kick', 'monday', 'news', 'ming', 'c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-11-05 00:00:00</td>\n",
       "      <td>morningstar.com</td>\n",
       "      <td>['share', 'trade', 'monday', 'follow', 'maker'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2018-11-05 12:45:00</td>\n",
       "      <td>seekingalpha.com</td>\n",
       "      <td>['portfolio', 'current', 'sit', 'core', 'divid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2018-11-26 00:00:00</td>\n",
       "      <td>morningstar.com</td>\n",
       "      <td>['cristina', 'ker', 'implement', 'sever', 'boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-11-23 00:00:00</td>\n",
       "      <td>zacks.com</td>\n",
       "      <td>['trade', 'high', 'three', 'major', 'stock', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0            timestamp            source  \\\n",
       "0           0  2018-11-14 12:12:00       9to5mac.com   \n",
       "1           1  2018-11-05 00:00:00   morningstar.com   \n",
       "2           2  2018-11-05 12:45:00  seekingalpha.com   \n",
       "3           3  2018-11-26 00:00:00   morningstar.com   \n",
       "4           4  2018-11-23 00:00:00         zacks.com   \n",
       "\n",
       "                                              tokens  \n",
       "0  ['thing', 'kick', 'monday', 'news', 'ming', 'c...  \n",
       "1  ['share', 'trade', 'monday', 'follow', 'maker'...  \n",
       "2  ['portfolio', 'current', 'sit', 'core', 'divid...  \n",
       "3  ['cristina', 'ker', 'implement', 'sever', 'boo...  \n",
       "4  ['trade', 'high', 'three', 'major', 'stock', '...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_amzn_news_df = pd.read_csv(\"AmznExtractedTokens.csv\")\n",
    "tokenized_aapl_news_df = pd.read_csv('AaplExtractedTokens.csv')\n",
    "\n",
    "tokenized_aapl_news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframes based on timestamps\n",
    "# tokenized_amzn_news_df.sort_values(['day', 'time'], axis=0, ascending=(True, True), inplace=True)\n",
    "# tokenized_aapl_news_df.sort_values(['day', 'time'], axis=0, ascending=(True, True), inplace=True)\n",
    "tokenized_amzn_news_df.sort_values(['timestamp'], axis=0, ascending=True, inplace=True)\n",
    "tokenized_aapl_news_df.sort_values(['timestamp'], axis=0, ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('AmznExtractedTokens.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenized_amzn_news_df, f)\n",
    "with open('AaplExtractedTokens.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenized_aapl_news_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP28kHTgHIiEimh6OnqOEzf",
   "collapsed_sections": [],
   "name": "swm-news-preprocess.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
